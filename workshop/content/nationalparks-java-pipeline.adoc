在本实验中，您将学习管道以及如何在OpenShift中配置管道，以便用它来管理应用程序的生命周期。

== 背景：持续集成和管道

持续交付(CD)管道是将软件从版本控制直接传递给用户和客户的过程的自动表达。对软件的每一个变更(在源代码控制中提交)在发布的过程中都要经历一个复杂的过程。这个过程包括以可靠和可重复的方式构建软件，以及通过测试和部署的多个阶段来推进构建的软件(称为 "构建" )。

OpenShift pipeline是一个基于云的持续集成和交付(CI/CD)解决方案，运用 https://tekton.dev/[Tekton] 来构建管道。Tekton是一个灵活的、Kubernetes原生的开源CI/CD框架，通过抽象底层细节，可以实现跨多个平台(Kubernetes、无服务器、vm等)的自动部署。

image::images/devops-pipeline-flow.png[Pipelines]

== 认识 Tekton

Tekton定义了许多 https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/custom-resources/[Kubernetes自定义资源] 作为构建块，以便标准化管道概念，并提供跨CI/CD解决方案的一致术语。

定义管道所需的自定义资源如下所示：

* `Task`: 执行特定任务(例如构建容器镜像)的可重用的、松散耦合的多个步骤
* `Pipeline`: 管道的定义和它应该执行的 `Tasks` 
* `TaskRun`: 任务实例运行的执行和结果
* `PipelineRun`: 管道实例的执行和结果，其中包括一些 `TaskRuns`

image::images/tekton-architecture.png[Tekton Architecture]

简而言之，为了创建一个管道，需要执行以下操作：

* 创建自定义或安装 https://github.com/tektoncd/catalog[现有] 可重用的 `Tasks`
* 创建一个 `Pipeline` 和 `PipelineResources` 来定义应用程序的交付管道
* 创建一个 `PersistentVolumeClaim` 来为管道执行提供卷/文件系统，或者提供 `VolumeClaimTemplate` 来创建一个 `PersistentVolumeClaim` 
* 创建一个 `PipelineRun` 来实例化和调用管道

有关管道概念的进一步详细信息，请参阅 https://github.com/tektoncd/pipeline/tree/master/docs#learn-more[Tekton文档] ，它为理解用于定义管道的各种参数和属性提供了很好的指南。

== 创建您的管道

由于管道提供了在交付周期的不同阶段之间提升应用程序的能力，Tekton是我们的持续集成服务器，它将被部署到一个具有持续集成角色的项目中，它将执行我们的管道。在这个项目中执行的管道将有权限与我们交付周期面向不同阶段的所有项目交互。

在这个例子中，我们将部署我们的管道，它存储在Gogs存储库中，也就是我们代码所在的地方。在更真实的场景中，为了遵循 https://en.wikipedia.org/wiki/Infrastructure_as_Code[基础设施作为代码] 原则，我们将存储所有管道定义以及我们将使用的每个OpenShift资源定义。


[source,shell,role=execute-1]
----
oc create -f http://gogs-{{INFRA_PROJECT}}.{{cluster_subdomain}}/{{username}}/nationalparks/raw/master/pipeline/nationalparks-pipeline-new.yaml -n {{project_namespace}}
----

验证您创建的管道：

[source,shell,role=execute-1]
----
oc get pipelines -n {{project_namespace}}
----

你应该看到这样的内容：

[source,bash]
----
NAME                     AGE
nationalparks-pipeline   8s
----

现在让我们查看一下Tekton Pipeline：

[source,shell,role=copypaste]
----
apiVersion: tekton.dev/v1beta1
kind: Pipeline
metadata:
  name: nationalparks-pipeline
spec:
  params:
    - default: nationalparks
      name: APP_NAME
      type: string
    - default: 'https://github.com/openshift-roadshow/nationalparks.git'
      description: The application git repository url
      name: APP_GIT_URL
      type: string
    - default: master
      description: The application git repository revision
      name: APP_GIT_REVISION
      type: string
  tasks:
    - name: git-clone
      params:
        - name: url
          value: $(params.APP_GIT_URL)
        - name: revision
          value: $(params.APP_GIT_REVISION)
        - name: submodules
          value: 'true'
        - name: depth
          value: '1'
        - name: sslVerify
          value: 'true'
        - name: deleteExisting
          value: 'true'
        - name: verbose
          value: 'true'
      taskRef:
        kind: ClusterTask
        name: git-clone
      workspaces:
        - name: output
          workspace: app-source
    - name: build-and-test
      params:
        - name: MAVEN_IMAGE
          value: gcr.io/cloud-builders/mvn
        - name: GOALS
          value:
            - package
        - name: PROXY_PROTOCOL
          value: http
      runAfter:
        - git-clone
      taskRef:
        kind: ClusterTask
        name: maven
      workspaces:
        - name: source
          workspace: app-source
        - name: maven-settings
          workspace: maven-settings
    - name: build-image
      params:
        - name: IMAGE
          value: image-registry.openshift-image-registry.svc:5000/$(context.pipelineRun.namespace)/$(params.APP_NAME):latest
        - name: BUILDER_IMAGE
          value: >-
            registry.redhat.io/rhel8/buildah@sha256:180c4d9849b6ab0e5465d30d4f3a77765cf0d852ca1cb1efb59d6e8c9f90d467
        - name: STORAGE_DRIVER
          value: vfs
        - name: DOCKERFILE
          value: ./Dockerfile
        - name: CONTEXT
          value: .
        - name: TLSVERIFY
          value: 'true'
        - name: FORMAT
          value: oci
      runAfter:
        - build-and-test
      taskRef:
        kind: ClusterTask
        name: buildah
      workspaces:
        - name: source
          workspace: app-source
    - name: redeploy
      params:
        - name: SCRIPT
          value: oc rollout restart deployment/$(params.APP_NAME)
      runAfter:
        - build-image
      taskRef:
        kind: ClusterTask
        name: openshift-client
  workspaces:
    - name: app-source
    - name: maven-settings
----

 `Pipeline` 是用户定义的CD管道模型。Pipeline的代码定义了整个构建过程，通常包括构建应用程序、测试应用程序和交付应用程序的各个阶段。

 `Task` 和 `ClusterTask` 包含一些要执行的步骤。 *ClusterTasks* 可用于安装了OpenShift管道的集群内的所有用户，而 *Tasks* 可以自定义。

TIP: 您可以从Web控制台和CLI中探索集群中所有可用的 *ClusterTasks* ：

[source,shell,role=execute-1]
----
oc get clustertasks
----

这个管道定义了4个任务：

- *git clone*: 这是一个 `ClusterTask` ，它将克隆我们的国家公园的代码存储库，并将其存储到一个 `Workspace` `app-source` ，这将使用为它创建的PVC `app-source-workspace`。
- *build-and-test*: 将使用 `maven` `ClusterTask` 构建和测试我们的Java应用程序。
- *build-image*: 这是一个链接: https://buildah.io/[buildah] ClusterTask将使用二进制文件作为OpenShift中的输入来构建镜像，在我们的例子中是在前一个Task中生成的JAR文件。
- *redeploy*: 它将使用 `openshift-client` 。ClusterTask将运用我们在之前的实验室中创建的名为 `nationalparks` 的Deployment来部署创建的镜像到OpenShift上。

从左侧菜单，点击 *Pipeline*，然后点击 *nationalparks-pipeline* ，查看您刚刚创建的管道。

image::images/devops-pipeline-created.png[Pipeline created]

Pipeline是参数化的，需要使用的参数使用默认值。

它使用了两个 *Workspaces*:

- *app-source*: 链接到一个 *PersistentVolumeClaim* `app-source-pvc` ，这个PVC是从前面命令中使用的YAML模板创建的。这将用于存储将在不同的 *Task* 中使用的工件。
- *maven-settings*: 一个 *EmptyDir* 卷用于maven缓存，这也可以用PVC扩展，使后续的maven构建更快。

== 练习：为管道添加存储

OpenShift管理存储链接: https://kubernetes.io/docs/concepts/storage/persistent-volumes/[持久卷] 通过 *Persistent Volume Claim* 请求被附加到运行我们的应用程序的Pods上，并且它还提供了从Web控制台轻松管理它的能力。

从 *Administrator Perspective*，转到 *Storage*-> *Persistent Volume Claims*。

转到右上角，单击 *Create Persistent Volume Claim* 按钮。

在 *Persistent Volume Claim name* 对话框填入 *app-source-pvc*。

在 *Size* 部分, 填入 *1* 因为我们要为管道创建1 GiB的持久卷, 使用RWO单用户访问模式。

保留所有其他默认设置，并单击 *Create*。

image::images/nationalparks-codechanges-pipeline-pvc.png[创建 PVC]

TIP: *Storage Class* 是集群中可用的存储类型。


== 运行管道

现在我们可以从Web控制台启动管道。从左侧菜单，点击 *Pipeline*，然后点击 *nationalparks-pipeline*。从右上角的 *Actions* 列表中，单击 *Start*。

image::images/devops-pipeline-start-1.png[Start Pipeline]

系统将提示您添加Pipeline的参数，并显示默认的参数。

在 *APP_GIT_URL* 中填入 `nationalparks` 您Gogs代码库的地址:

[source,role=copypaste]
----
http://gogs-{{INFRA_PROJECT}}.{{cluster_subdomain}}/{{username}}/nationalparks.git
----

在 *Workspaces*-> *app-source* 中的列表中选择 *PVC* ，然后选择 *app-source-pvc*。这是管道中包含源代码和编译工件的管道任务所使用的共享卷。

点击 *Start* 来运行您的管道。

image::images/devops-pipeline-start-2.png[Add parameters]


您可以从 *Pipeline* 部分跟踪管道执行，查看所有进行中的步骤。点击 *Pipeline Runs* 选项卡查看它的运行情况：

image::images/devops-pipeline-run-1.png[Pipeline running]

点击 `PipelineRun` *national-parks-deploy-run-*：

image::images/devops-pipeline-run-java-2.png[Pipeline running animation]

然后点击正在运行的 *Task* 来检查日志：

image::images/devops-pipeline-run-java-3.png[Pipeline Task log]

验证PipelineRun已经成功完成：

image::images/devops-pipeline-run-java-4.png[PipelineRun completed]
